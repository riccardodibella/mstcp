Domande:
- Abbiamo detto che ha senso introdurre un buffer di trasmissione, da cui i dati vengono consumati da qualcosa di
analogo allo scheduler del Multi-Stream (ma più semplice), anche per TCP normale. Come dimensiono questo buffer?
Metto una dimensione fissa uguale per TX buffer e RX buffer per ogni stream o faccio qualcosa di diverso? Prima
c'erano i due parametri TXBUFSIZE e RXBUFSIZE, ma il primo non veniva usato effettivamente per la dimensione di
un buffer, solo per inizializzare il campo txfree dei TCB.
- Se non sbaglio, al momento il retransmission timer può andare da 300ms a 2000 tick (10s). Da dove arrivano
questi valori?
- Bisogna cambiare il modo di aggiornare l'RTT adesso che si considerano più misure per ogni ciclo di RTT invece
che solo una? Ho letto qualche discussione a riguardo, ma non ho trovato nessuna indicazione precisa
- A cosa serve l'ACK che viene inviato quando viene fatto myaccept?
- Nel paper è scritto, per l'apertura dei nuovi stream, di aspettare un timeout, e se non vengono inviati dati
entro quel timeout aprire lo stream con un pacchetto con il flag dummy payload. Faccio comunque ritornare connect() 
subito, senza aspettare di avere lo stream aperto, giusto? Sennò non posso inviare dati se sono fermo dentro connect.
- Sempre riguardo al timer dell'apertura degli stream, ho aggiunto un campo stream_fsm_timer ad ogni stream,
che viene usato per salvarmi a che valore di "tick" devo inviare il pacchetto con flag dummy payload se non è
ancora stato inviato nessun dato. Probabilmente può essere accorpato in qualche modo con il timer di canale usato
per la chiusura della connessione, ma finchè non faccio quella parte è più comodo tenerli separati. Ha senso?
- Non ho ancora iniziato a fare la parte di ricezione, ma vorrei capire se è giusto come penso di impostarla:
    - nel paper viene messo solo un buffer di trasmissione (consumato dallo scheduler), non un buffer di ricezione
    in cui inserire i dati quando arrivano. A seconda di se si voglia aggiungere questo buffer di ricezione o meno
    ci sono due casi possibili:
    - se si vuole aggiungere il buffer di ricezione: 
        - c'è un buffer di ricezione diverso per ogni stream
        - dato che il flusso dei seq number è associato alla connessione intera, non posso usare quello per inserire
        "a colpo sicuro" i dati nel buffer di ricezione
        - se arriva un segmento con un SSN immediatamente successivo all'ultimo ricevuto, lo aggiungo all'inizio dello
        spazio libero nel buffer dello stream
        - se un segmento ha il flag dummy payload, non lo aggiungo mai al buffer
        - in questo caso, la advertised window è uguale allo spazio libero nel buffer per lo stream
    - se non si vuole mettere il buffer in ricezione:
        - c'è una linked list per il canale, che contiene i pacchetti ricevuti out-of-order, in cui rimangono fino a
        che il buco nel sequence number non viene riempito da un altro segmento
        - c'è una linked list per ogni stream, con i segmenti per quello stream il cui payload deve ancora essere
        consumato completamente
        - quando arriva un nuovo segmento, oltre a inserirlo nella linked list di canale, se il suo SSN è immediatamente
        successivo all'ultimo ricevuto per quello stream, lo inserisco alla fine della linked list di stream, con NULL
        come nodo successivo
        - dopo avere inserito un nodo (per la sua ricezione o per un segmento precedente che ha riempito il buco degli SSN)
        nella linked list di stream, percorro la linked list di canale per cercare il primo segmento per lo stesso stream;
        se il SSN è immediatamente successivo a quello appena inserito inserisco anche quel segmento, e ripeto la procedura
        fino a che il primo segmento non è immediatamente successivo o arrivo alla fine della channel rx linked list senza
        trovare altri segmenti sullo stream
        - ogni nodo della linked list di stream (che contengono il payload dei segmenti) ha un campo che mi dice quanti byte
        di payload ho già consumato con read(), quando questo valore arriva alla lunghezza del payload del segmento lo tolgo
        dalla lista, e tolgo dalla lista anche i segmenti all'inizio che hanno il flag dummy payload


{
    Devo capire cosa fare con i TCB dei passive open... Al momento è facile: quando faccio accept libero il posto
    nella backlog e ho una copia di quel TCB linkata solo in fdinfo per quel socket. Posso tenere la stessa cosa
    anche adesso nelle connessioni non-MS. Per le connessioni MS, non posso togliere il TCB dalla backlog
    fino a quando non ho riempito tutti e 32 gli stream (ma per consistenza non lo toglierei proprio mai dalla
    backlog finchè la connessione non è chiusa). Quando faccio accept(), linko in fdinfo[s] lo stesso TCB.
    Quando faccio la chiusura di uno stream, so che non devo chiudere la connessione a meno che quando mi arriva
    l'ACK della mia chiusura dello stream non siano stati chiusi gli stream, in quel caso posso chiuderla.
    Quando chiudo la connessione cancello anche la entry dalla backlog.
}


Risposte:
- Se devo mandare un ACK senza payload, lo associo allo stream 0?
    => NO, non inserire proprio l'opzione MS, in questo modo non si consuma un segment sequence number, che va bene
    dato che non si sta facendo avanzare il sequence number e quindi non ci interessa avere un ACK dell'ACK che si
    sta inviando
- La stima iniziale dell'RTT (lato active open) la faccio già considerando il SYN+ACK, giusto?
    => Probabilmente no, ma serve leggere sull'RFC (RFC 6298)
- Una volta che ho una sequenza di misure dell'RTT, come si calcola la stima dell'RTT da usare per il timeout?
    => Stesso meccanismo di mytcp, con rtt_e e Drtt_e (RFC 6298)
- Non devo tenere nessuno stato relativo ai SACK ricevuti, giusto? Quando ricevo un SACK libero lo spazio di quel 
pacchetto dalla flightsize dello stream corrispondente (e evito di ritrasmetterlo), ma è inutile salvare una "lista
di SACK ricevuti dopo il cumulative ACK" giusto?
    => Esatto
- A quanto avevamo detto, in MS c'è uno scheduler che man mano che appena si libera spazio nella congestion window
cerca di riempirlo con i dati dai tx buffer di ogni stream. Questo meccanismo del tx buffer non c'era nel tcp normale,
in cui i dati venivano segmentati direttamente ed inseriti subito nella tx queue. Metto lo stesso meccanismo anche nel
TCP normale, quindi introduco anche lì un TX buffer (che sarà associato solo allo stream 0 invece di essere per ogni
stream), oppure lascio così com'è e non creo nessun TX buffer per tcp normale?
    => Va bene inserire lo stesso meccanismo con un buffer e un "consumatore" (equivalente allo scheduler di MS-TCP) 
    anche in TCP normale
- Mi serve qualcosa di diverso da STREAM_STATE_CLOSED per gestire il broken pipe per backlog piena?
    => Credo basti STREAM_STATE_CLOSED


Fonti:
https://www.rfc-editor.org/rfc/rfc7323#section-4 Spiegazione di quali misure dell'RTT vanno usate per l'aggiornamento

Problemi di MYTCP:
- Il bind automatico in mybind di mytcp non fa htons() per salvare in fdinfo[s].l_port
- Problema con il timer per il timeout se non si specifica il timeout iniziale in mytcp
- Il ciclo che toglie i pacchetti di cui si è ricevuto l'ack toglie l'ACK del 3-way handshake
- Confermo che viene accettata solo una connessione alla volta
- In myaccept, viene dato errore se lo stato del TCB è SYN_RECEVIED, anche se c'è il toggle tra i due stati
- In myio, dopo aver chiamato la FSM, se la connessione non è established viene fatto "break" invece di "continue"